{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import time\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Save path for extracted features\n",
    "save_address_1024 = '/path/to/save/features/features_from_resnet50/'\n",
    "\n",
    "# Transformation for input patches\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom Dataset class\n",
    "class My_dataloader(Dataset):\n",
    "    def __init__(self, data_24, transform):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_24: Path to input data (slide directory).\n",
    "        \"\"\"\n",
    "        self.data_24 = data_24\n",
    "        self.pathes_24 = glob(self.data_24 + '/*')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pathes_24)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_24 = Image.open(self.pathes_24[idx]).convert('RGB')\n",
    "        img_24_name = os.path.basename(self.pathes_24[idx])\n",
    "        img_24_folder = os.path.basename(os.path.dirname(self.pathes_24[idx]))\n",
    "        if self.transform:\n",
    "            img_24 = self.transform(img_24)\n",
    "        return img_24, img_24_name, img_24_folder\n",
    "\n",
    "# Load ResNet50\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all layers initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze last 50 layers only\n",
    "for param in list(model.parameters())[-30:]:\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Modify feature extractor to include AdaptiveAvgPool2d\n",
    "# model.features = nn.Sequential(model.features, nn.AdaptiveAvgPool2d(output_size=(1, 1)))\n",
    "\n",
    "# Modify the average pooling layer\n",
    "model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))  # Correct modification\n",
    "\n",
    "# Reduce features from 2048 → 512 using a linear projection\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 512),  # ResNet50 outputs 2048-dimensional features\n",
    "    nn.ReLU(inplace=True),\n",
    ")\n",
    "\n",
    "# Set num_ftrs to 512 (new feature size)\n",
    "num_ftrs = 512\n",
    "\n",
    "\n",
    "# Define Custom Fully Connected Model\n",
    "class fully_connected(nn.Module):\n",
    "    def __init__(self, model, num_ftrs, num_classes):\n",
    "        print(f\"Input features: {num_ftrs}, Output classes: {num_classes}\")\n",
    "        super(fully_connected, self).__init__()\n",
    "        self.model = model\n",
    "        self.fc_4 = nn.Linear(num_ftrs, num_classes)  # Now input is 512 instead of 1280\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        out_1 = x  # 512-dimensional features\n",
    "        out_3 = self.fc_4(x)  # Classification output\n",
    "        return out_1, out_3\n",
    "\n",
    "\n",
    "# Define Final Model\n",
    "model_final = fully_connected(model, num_ftrs, 4)\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_final = model_final.to(device)\n",
    "model_final = nn.DataParallel(model_final)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def test_model(model, criterion, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    model.eval()   # Setting in evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    # Processing pipeline\n",
    "    class_dirs = glob(\"/path/to/patches/...\")  \n",
    "\n",
    "    for class_dir in class_dirs:\n",
    "        class_name = os.path.basename(class_dir)  \n",
    "        slide_paths = glob(os.path.join(class_dir, '*')) \n",
    "\n",
    "        # Create directory for class in save path\n",
    "        class_save_path = os.path.join(save_address_1024, class_name)\n",
    "        os.makedirs(class_save_path, exist_ok=True)\n",
    "\n",
    "        for slide_path in slide_paths:\n",
    "            slide_name = os.path.basename(slide_path) \n",
    "            print(f\"Processing Slide: {slide_name} in Class: {class_name}\")\n",
    "\n",
    "            # Create dataset and dataloader for the slide\n",
    "            test_imagedataset = My_dataloader(slide_path, trans)\n",
    "            dataloader_test = torch.utils.data.DataLoader(test_imagedataset, batch_size=600, shuffle=False, num_workers=16)\n",
    "\n",
    "            # Initialize dictionary to store features\n",
    "            slide_patches_dict_1024 = {}\n",
    "\n",
    "            # Extract features for all patches in the slide\n",
    "            for ii, (inputs, img_name, folder_name) in enumerate(dataloader_test):\n",
    "                print(\"Batch count:\", ii)\n",
    "                print(\"Input shape:\", inputs.shape)\n",
    "                inputs = inputs.to(device)\n",
    "                output1, outputs = model(inputs)\n",
    "                output_1024 = output1.cpu().detach().numpy()\n",
    "\n",
    "                # Save features in the dictionary\n",
    "                for j in range(len(outputs)):\n",
    "                    slide_patches_dict_1024[img_name[j]] = output_1024[j]\n",
    "\n",
    "            # Save features to a pickle file in the class-specific directory\n",
    "            output_file_name = f\"{slide_name}_resnet50Features_dict.pickle\"\n",
    "            output_file_path = os.path.join(class_save_path, output_file_name)\n",
    "            with open(output_file_path, 'wb') as outfile:\n",
    "                pickle.dump(slide_patches_dict_1024, outfile)\n",
    "                print(f\"Saved features to: {output_file_path}\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Evaluation completed in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    return model\n",
    "\n",
    "# Call the test_model function\n",
    "test_model(model_final, criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get combined hd5 file for all classes features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing the .pickle files\n",
    "pickle_dir = '/path/to/features/features_from_resnet50'\n",
    "h5_output_file = '/path/to/save/features/features_from_resnet50/features_resnet50.hdf5'\n",
    "\n",
    "# Label mapping for classes\n",
    "class_labels = {\"TCIA-normal\": 0, \"osmf_oscc\": 1, \"OSMF\": 1, \"wd\": 1, \"tcia-wd\": 1, \"md\": 2, \"tcia-md\": 2, \"pd\": 3, \"tcia-pd\": 3, 'Normal_aug_all_TCIA_inhouse': 0} \n",
    "\n",
    "# Function to extract (row, col) from patch name\n",
    "def extract_coords_from_patch_name(patch_name):\n",
    "    print(\"patch_name\", patch_name)\n",
    "    try:\n",
    "        parts = patch_name.replace('.png', '').split('_')  # Remove .png and split by _\n",
    "        \n",
    "        if 'tile' in parts:\n",
    "            tile_idx = parts.index('tile')\n",
    "            row = int(parts[tile_idx + 1])  # Extract row number\n",
    "            col = int(parts[tile_idx + 2])  # Extract column number\n",
    "            return (row, col)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected format in patch name\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing patch name {patch_name}: {e}\")\n",
    "        return (0, 0)  \n",
    " \n",
    "\n",
    "# Create HDF5 file\n",
    "with h5py.File(h5_output_file, 'w') as h5_file:\n",
    "    # Loop through class directories\n",
    "    for class_dir in os.listdir(pickle_dir):\n",
    "        class_path = os.path.join(pickle_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            # Process each slide in the class directory\n",
    "            for pickle_file in os.listdir(class_path):\n",
    "                if pickle_file.endswith('.pickle'):\n",
    "                    slide_name = os.path.splitext(pickle_file)[0]\n",
    "                    slide_id = slide_name.split('_')[0]  # Extract slide_id\n",
    "                    slide_path = os.path.join(class_path, pickle_file)\n",
    "                    print(f\"Processing slide: {slide_name} (Slide ID: {slide_id})\")\n",
    "\n",
    "                    # Load .pickle file\n",
    "                    with open(slide_path, 'rb') as f:\n",
    "                        patch_features = pickle.load(f)\n",
    "\n",
    "                    # Extract embeddings and coordinates\n",
    "                    embeddings = []\n",
    "                    coords = []\n",
    "                    for patch_name, feature in sorted(patch_features.items()):  \n",
    "                        embeddings.append(feature)\n",
    "                        coords.append(extract_coords_from_patch_name(patch_name))\n",
    "\n",
    "                    embeddings = np.array(embeddings)\n",
    "                    coords = np.array(coords)\n",
    "\n",
    "                    # Create HDF5 group for the slide\n",
    "                    group = h5_file.create_group(slide_name)\n",
    "                    group.create_dataset(\"embeddings\", data=embeddings)\n",
    "                    group.create_dataset(\"coords\", data=coords)\n",
    "                    group.create_dataset(\"label\", data=class_labels[class_dir])\n",
    "                    group.attrs[\"slide_id\"] = slide_id  \n",
    "                    group.attrs[\"path\"] = slide_name   \n",
    "                    # group.attrs[\"slide_id\"] = slide_id \n",
    "\n",
    "                    print(f\"Saved {slide_name} (Slide ID: {slide_id}) to HDF5.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODIFIED HDF5 CREATION SCRIPT (for Multi-class OSCC Grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Paths\n",
    "pickle_dir = '/path/to/features/features_organized_by_class'\n",
    "h5_output_file = '/path/to/save/features/oscc_grading_features_resnet50.hdf5'\n",
    "\n",
    "# Label mapping\n",
    "class_labels = {\n",
    "    \"2\": 2,  # WD\n",
    "    \"3\": 3,  # MD\n",
    "    \"4\": 4   # PD\n",
    "}\n",
    "\n",
    "# Extract patch coords from name\n",
    "def extract_coords_from_patch_name(patch_name):\n",
    "    try:\n",
    "        parts = patch_name.replace('.png', '').split('_')\n",
    "        if 'tile' in parts:\n",
    "            tile_idx = parts.index('tile')\n",
    "            return int(parts[tile_idx + 1]), int(parts[tile_idx + 2])\n",
    "        return (0, 0)\n",
    "    except Exception:\n",
    "        return (0, 0)\n",
    "\n",
    "# Start HDF5 creation\n",
    "with h5py.File(h5_output_file, 'w') as h5_file:\n",
    "    total_saved = 0\n",
    "    skipped = []\n",
    "\n",
    "    for class_folder in os.listdir(pickle_dir):\n",
    "        class_path = os.path.join(pickle_dir, class_folder)\n",
    "        if not os.path.isdir(class_path) or class_folder not in class_labels:\n",
    "            continue\n",
    "\n",
    "        label = class_labels[class_folder]\n",
    "\n",
    "        for pickle_file in os.listdir(class_path):\n",
    "            if not pickle_file.endswith(\".pickle\"):\n",
    "                continue\n",
    "\n",
    "            slide_name = pickle_file.replace(\"_resnet50Features_dict.pickle\", \"\")\n",
    "            slide_path = os.path.join(class_path, pickle_file)\n",
    "\n",
    "            try:\n",
    "                with open(pickle_path := slide_path, 'rb') as f:\n",
    "                    patch_features = pickle.load(f)\n",
    "\n",
    "                if not patch_features:\n",
    "                    print(f\" Skipped (empty features): {slide_name}\")\n",
    "                    skipped.append(slide_name)\n",
    "                    continue\n",
    "\n",
    "                embeddings = []\n",
    "                coords = []\n",
    "\n",
    "                for patch_name, feature in sorted(patch_features.items()):\n",
    "                    if feature is not None:\n",
    "                        embeddings.append(feature)\n",
    "                        coords.append(extract_coords_from_patch_name(patch_name))\n",
    "\n",
    "                if len(embeddings) == 0:\n",
    "                    print(f\"⚠️ Skipped (no valid patches): {slide_name}\")\n",
    "                    skipped.append(slide_name)\n",
    "                    continue\n",
    "\n",
    "                embeddings = np.array(embeddings)\n",
    "                coords = np.array(coords)\n",
    "\n",
    "                group = h5_file.create_group(slide_name)\n",
    "                group.create_dataset(\"embeddings\", data=embeddings)\n",
    "                group.create_dataset(\"coords\", data=coords)\n",
    "                group.create_dataset(\"label\", data=label)\n",
    "                group.attrs[\"slide_name\"] = slide_name\n",
    "                group.attrs[\"label\"] = label\n",
    "\n",
    "                print(f\" Saved slide {slide_name} with {embeddings.shape[0]} patches.\")\n",
    "                total_saved += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in slide {slide_name}: {e}\")\n",
    "                skipped.append(slide_name)\n",
    "\n",
    "print(f\"\\n✅ HDF5 creation complete. Total saved: {total_saved}\")\n",
    "print(f\"⚠️ Slides skipped: {len(skipped)}\")\n",
    "if skipped:\n",
    "    print(\"   Examples:\", skipped[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
